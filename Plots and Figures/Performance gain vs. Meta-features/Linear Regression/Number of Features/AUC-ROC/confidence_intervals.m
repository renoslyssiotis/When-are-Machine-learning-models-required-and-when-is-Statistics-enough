clear all
x =     [10,   10,   10,   10,   10,    4,    4,    4,    4,    4,    4,...
          4,    4,    4,    4,    5,    5,    5,    5,    5,    9,    9,...
          9,    9,    9,    9,    9,    9,    9,    9,   10,   10,    2,...
         10,   10,   13,   13,   13,   13,   13,    6,    6,    6,    6,...
          6,   34,   34,   34,   34,   34,    9,    9,    9,    9,    9,...
         22,   22,   22,   22,   22,    7,    7,    7,    7,    7,    8,...
          8,    8,    8,    8,   11,   11,   11,   11,   11,    3,    3,...
          3,    3,    3,   60,   60,   60,   60,   60,   57,   57,   57,...
         57,   57,   16,   16,   16,   16,   16,    6,    6,    6,    6,...
          6,   19,   19,   19,   19,   19,   24,   24,   24,   24,   24,...
          2,    2,    2,    2,    2,   24,   24,   24,   24, 2000, 2000,...
       2000, 2000, 2000,    8,    8,    8,    8,    8,    8,    8,    8,...
          8,    8,    8,    8,    8,    8,    8,    7,    7,    7,    7,...
          7,   14,   14,   14,   14,   14,   14,   14,   14,   14,   14,...
          7,    7,    7,    7,    7,   31,   31,   31,   31,   31,    5,...
          5,    5,    5,    5,   22,   22,   22,   22,   22,   74,   74,...
         74,   74,   74,   10,   10,   10,   41,   41,   41,   41,   41,...
         18,   18,   18,   18,   18,   12,   12,   12,   12,   12,   10,...
         10,   10,   10,   10];
    
y =    [0.31534141,  0.26725182,  0.29048254,  0.30581133,  0.31631892,...
        0.        ,  0.01612903,  0.        ,  0.00625   ,  0.01460655,...
        0.12211456,  0.03968254,  0.10130719,  0.15846154,  0.125     ,...
        0.        ,  0.        ,  0.06335283,  0.01944444,  0.05288958,...
        0.16666667,  0.        ,  0.25      ,  0.25      ,  0.20555556,...
        0.16666667,  0.08333333,  0.        ,  0.        ,  0.16666667,...
        0.05556189,  0.03070877,  0.05556725,  0.05336842,  0.07474359,...
        0.01470588,  0.        , -0.03525641,  0.04347826, -0.025     ,...
       -0.125     ,  0.25      ,  0.        ,  0.07142857,  0.05      ,...
        0.        ,  0.        ,  0.04166667,  0.        ,  0.        ,...
        0.09375   ,  0.10714286,  0.5       ,  0.5       ,  0.        ,...
        0.04227891,  0.04461197,  0.03618685,  0.04718784,  0.04349627,...
        0.2       ,  0.5       ,  0.        ,  0.2       ,  0.13888889,...
        0.06055556,  0.20227273,  0.02777778,  0.03276353,  0.04444444,...
        0.        ,  0.16666667,  0.16666667,  0.08333333,  0.03174603,...
        0.11585358,  0.11265386,  0.11788387,  0.11627835,  0.11519371,...
        0.07451923,  0.        ,  0.26515152,  0.1       ,  0.14642857,...
        0.0352953 ,  0.07600964,  0.03943489,  0.02259735,  0.04252657,...
        0.15178571,  0.025     ,  0.07142857,  0.14583333,  0.03639847,...
        0.04645761,  0.0625    ,  0.        ,  0.02693603,  0.15808824,...
        0.0803638 ,  0.05555556,  0.07894737,  0.05178571,  0.01342593,...
        0.18558374,  0.13714859,  0.1868315 ,  0.19470261,  0.17500136,...
        0.36410094,  0.42045455,  0.45131684,  0.365699  ,  0.39302624,...
        0.07692308,  0.01666667,  0.02535302,  0.01567024,  0.1       ,...
        0.        ,  0.        ,  0.        ,  0.1       ,  0.43030303,...
        0.2       ,  0.01818182,  0.01028708,  0.01700581,  0.01672557,...
        0.0155936 ,  0.00649932,  0.00163391,  0.01555355,  0.0938409 ,...
        0.13111888,  0.20776463,  0.07349896,  0.07339483,  0.07638889,...
        0.        ,  0.        ,  0.        ,  0.        ,  0.03125   ,...
        0.2       ,  0.1       ,  0.        ,  0.        ,  0.30265223,...
        0.19363721,  0.28137433,  0.30076042,  0.28801039,  0.015625  ,...
        0.16666667,  0.        ,  0.02272727,  0.01666667,  0.06773119,...
        0.19740778,  0.15947612,  0.14365751,  0.0440548 ,  0.03035167,...
        0.0625    ,  0.015625  ,  0.03125   , -0.00079365,  0.13636364,...
        0.16666667,  0.04166667,  0.08403361,  0.04      ,  0.        ,...
        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,...
        0.        ,  0.        ,  0.01880927,  0.01724138,  0.00961538,...
        0.01720867,  0.025     ,  0.025     ,  0.025     , -0.0125    ,...
        0.10860656,  0.00641026,  0.11188811,  0.33333333,  0.375     ,...
        0.04166667,  0.16402715,  0.16402715,  0.16402715,  0.16402715,...
        0.13622291,  0.09068323];

xs = linspace(0,100,101)';

meanfunc = [];                    % empty: don't use a mean function
covfunc = @covSEiso;              % Squared Exponental covariance function
likfunc = @likGauss;              % Gaussian likelihood

%Initialise hyperparameters structure
hyp = struct('mean', [], 'cov', [-1 -1], 'lik',0);
hyp2 = minimize(hyp, @gp, -100, @infGaussLik, meanfunc, covfunc, likfunc, x,y);
K = feval(covfunc, hyp2.cov, x);
%Obtain the predictive mean and variance of test points
[mu,s2] = gp(hyp2, @infGaussLik, meanfunc, covfunc, likfunc,x,y,xs);

%Compute the (joint) negative log probability (density): nlml
nlml = gp(hyp2, @infGaussLik, meanfunc, covfunc, likfunc, x, y);
%Plot the predictive mean with predictive 95% confidence bounds and training data
f = [mu+2*sqrt(s2); flip(mu-2*sqrt(s2),1)];
fill([xs; flip(xs,1)], f, [7 7 7]/8)
hold on; plot(xs, mu, 'b'); plot(x,y,'r.','LineWidth',1)
xlabel('﻿Number of features','FontSize',14)
ylabel('﻿Performance gain of ML vs. Statistics','FontSize',14)
a = get(gca,'XTickLabel');
b = get(gca,'YTickLabel');
set(gca,'XTickLabel',a,'fontsize',14)
set(gca,'XTickLabel',b,'fontsize',14)
title('﻿Performance gain (AUC-ROC) vs. Number of features','FontSize',14)
legend('95% predictive error bars', 'Predictive mean', 'Data', 'FontSize',12)
xlim([0 100]);
xticks([0 20 40 60 80 100]);
xticklabels({0,20,40,60,80,100}) 