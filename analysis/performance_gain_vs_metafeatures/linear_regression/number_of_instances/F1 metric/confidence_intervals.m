clear all
x = [1372,  274,  549,  823, 1098,  748,  150,  299,  449,  598,  569,...
        114,  228,  341,  455,  116,   35,   46,   70,   93,  106,   32,...
         42,   64,   85, 2000,  303,   61,  121,  182,  242,   90,   18,...
         36,   54,   72,  357,   71,  143,  214,  286,  100,   45,   50,...
         60,   80, 1439,   90,   18,   36,   54,   72,  768,  154,  307,...
        461,  614,  187,   37,   75,  112,  150,  208,   42,   83,  125,...
        166,  920, 1840,  470,   94,  188,  282,  376,  310,   62,  124,...
        186,  248, 1340,  268,  536,  804, 1072, 1060,  200,  400,  600,...
        800,   62,   12,   25,   37,   50,  767,  154,  307,  461,  614,...
        835, 1671,  210,   42,   84,  126,  168,  142,   28,   57,   85,...
        114,  336,   67,  134,  202,  269, 1885,  377,  754, 1131, 1508,...
        828,  166,  331,  497,  662,  195,   39,   78,  117,  156, 1047,...
        209,  419,  628,  838,   25,   10,   20, 1055,  211,  422,  633,...
        844,  540,  108,  216,  324,  432,  182,   36,   73,  109,  146,...
        579,  116,  232,  347,  463];
y = [0.00000000e+00,  1.81453207e-02,  0.00000000e+00,  6.06194350e-03,...
        1.36458752e-02,  7.84118348e-02,  5.70697844e-02,  3.62962963e-02,...
        7.39754570e-02,  8.14965172e-02,  0.00000000e+00,  0.00000000e+00,...
        6.52667772e-02,  1.57901487e-03,  4.57828394e-02,  1.68997669e-01,...
        0.00000000e+00,  2.19047619e-01,  2.27350427e-01,  2.08732057e-01,...
        4.80870481e-02,  1.25541126e-01,  0.00000000e+00,  0.00000000e+00,...
        6.19358855e-02,  2.23759916e-02,  1.61580782e-02,  0.00000000e+00,...
       -3.80676329e-02,  5.11954262e-02, -2.07574686e-02, -1.11111111e-01,...
        2.66666667e-01,  0.00000000e+00,  8.93550894e-02,  6.49405061e-02,...
        0.00000000e+00,  0.00000000e+00,  3.47397730e-02,  0.00000000e+00,...
        0.00000000e+00,  6.14379085e-02,  6.62393162e-03,  1.47368421e-01,...
        1.23188406e-01,  0.00000000e+00,  4.16666667e-02,  1.60449735e-01,...
        6.66666667e-01,  0.00000000e+00,  2.11433011e-01,  1.49482402e-01,...
        5.18233234e-02,  1.60589060e-01,  1.80079969e-02,  2.86922793e-02,...
        3.77433293e-02,  0.00000000e+00,  2.16666667e-01,  6.73348391e-02,...
        1.76251241e-01,  2.83838384e-02,  7.03127264e-02,  0.00000000e+00,...
        2.96638655e-01,  1.18067633e-01,  1.46148645e-01,  7.14209304e-02,...
        3.32222838e-02,  3.88194459e-02,  0.00000000e+00,  3.82039014e-02,...
        6.32149896e-02,  3.42076565e-02,  1.54687185e-02,  7.59906760e-02,...
        0.00000000e+00,  2.48689907e-02,  1.02921258e-01,  4.16286082e-02,...
        5.35183070e-02,  2.07959045e-02,  1.27532376e-02, -1.13678624e-02,...
        4.15248315e-01,  5.50440252e-02,  4.79417741e-03,  2.46037296e-02,...
        1.51282227e-02,  8.55957768e-02,  0.00000000e+00,  0.00000000e+00,...
        0.00000000e+00,  7.89341378e-02,  3.83493236e-01,  1.65981025e-01,...
        0.00000000e+00,  0.00000000e+00,  1.14984193e-02,  2.15351381e-02,...
        1.58025723e-02,  7.28902470e-02,  0.00000000e+00,  0.00000000e+00,...
        0.00000000e+00,  0.00000000e+00,  3.57963875e-02,  2.91666667e-01,...
        8.15850816e-02,  0.00000000e+00,  0.00000000e+00,  1.47538467e-02,...
        2.08791209e-01,  0.00000000e+00,  2.44483159e-02,  1.83290276e-02,...
        9.32866953e-03,  9.00915010e-02,  3.58516083e-02,  6.13239771e-02,...
       -1.46664744e-03,  2.52793259e-02,  5.94893422e-02,  1.52601265e-02,...
        3.03587579e-02, -1.35470488e-05,  9.42078590e-02,  1.31818182e-01,...
        6.03864734e-02,  1.44675926e-02,  5.79427516e-02,  0.00000000e+00,...
        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,...
        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  1.79944010e-02,...
        2.20811652e-02,  1.13864028e-02,  1.55308743e-02,  2.32288037e-02,...
        2.32288037e-02,  2.32288037e-02, -1.87206733e-02, -8.13116502e-03,...
        1.03694142e-02,  9.56670957e-02,  2.82051282e-01,  2.41855072e-01,...
       -3.22920323e-02,  1.47730287e-02,  1.47730287e-02,  1.47730287e-02,...
        1.47730287e-02,  5.16067266e-02,  3.28647794e-02];
xs = linspace(0,2000,2001)';
meanfunc = [];                    % empty: don't use a mean function
covfunc = @covSEiso;              % Squared Exponental covariance function
likfunc = @likGauss;              % Gaussian likelihood

%Initialise hyperparameters structure
hyp = struct('mean', [], 'cov', [-1 0], 'lik',0);
hyp2 = minimize(hyp, @gp, -100, @infGaussLik, meanfunc, covfunc, likfunc, x,y);
K = feval(covfunc, hyp2.cov, x);
%Obtain the predictive mean and variance of test points
[mu,s2] = gp(hyp2, @infGaussLik, meanfunc, covfunc, likfunc,x,y,xs);

%Compute the (joint) negative log probability (density): nlml
nlml = gp(hyp2, @infGaussLik, meanfunc, covfunc, likfunc, x, y);
%Plot the predictive mean with predictive 95% confidence bounds and training data
f = [mu+2*sqrt(s2); flip(mu-2*sqrt(s2),1)];
fill([xs; flip(xs,1)], f, [7 7 7]/8)
hold on; plot(xs, mu, 'b'); plot(x,y,'r.','LineWidth',1)
xlabel('﻿Number of instances','FontSize',14)
ylabel('﻿Performance gain of ML vs. Statistics','FontSize',14)
a = get(gca,'XTickLabel');
b = get(gca,'YTickLabel');
set(gca,'XTickLabel',a,'fontsize',14)
set(gca,'XTickLabel',b,'fontsize',14)
title('﻿Performance gain (f1 metric) vs. Number of instances','FontSize',14)
legend('95% predictive error bars', 'Predictive mean', 'Data', 'FontSize',12)
xlim([0 2000]);
xticks(linspace(0,2000,10));


